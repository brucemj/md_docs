# 运维 开发


## Linux ##
1. Linux常用命令
	- 熟悉linux/Unix或Windows系统管理
	- 对系统性能有一定的认识；对服务器硬件知识有一定的了解；

2. awk, sed, grep, strace, tcpdump, gdb, iptables
	- 熟悉网络知识，了解tcp/ip协议,能够使用tcpdump捉包分析问题；
    - 5. 具备故障分析和处理能力，能熟练使用相关分析命令和工具，如mtr、tcpdump、strace、netstat、iperf、dstat、iostat、top、sar、vmstat、dig等

3. linux监控系统:  ganglia , zabbix , nagios , Prometheus , cacti
	- open-Falcon -- 整个系统的后端，全部golang编写，portal和dashboard使用python编写。
		- [Falcon文档](https://book.open-falcon.org/zh/intro/index.html)

4. 自动化运维 ： Ansible，Puppet等自动化运维工具

5. 有新一代应用设计、开发和运维经验，例如Container、Kubernetes 、DevOps、CD/CI等；

## 常用架构 ##
1. apache, nginx , tomcat ,  lvs , haproxy , Squid , sftp
	- 熟悉大型Web系统架构，以及相关应用的部署调优，包括：Web服务器、负载均衡、消息队列、数据库、高可用解决方案等；

2. mysql , redis , memcache, mogondb 等
	- 精通mysql数据库配置、备份、优化、监控

3. cvm，docker , rabbitmq 等虚拟化技术


## 编程语言 ##
	- 能使用shell/perl/python等脚本语言进行简单的程序编写；
	- 能编写运维工具；
	- 熟练掌握分布式计算原理
	- https://github.com/taizilongxu/interview_python  python面试题整理
	- http://python.jobbole.com/85231/   很全的 Python 面试题


## 大数据 ##
	- 熟练使用Hadoop，Hive，Spark，HBase等分布式系统
	- 研究过Hadoop或者Spark源代码的优先



## 知识 ##
- 线性代数很重要。
- 熟悉IT管理方法论，至少对 ITIL\Devops\ITOM中的两种有较为深刻的认识
- Operations Service Clerk  ------OPS部门，是属于内部服务性质的部门 -- 运维
- [Anaconda](https://www.anaconda.com/what-is-anaconda/)
	- With over 4.5 million users, Anaconda is the world’s most popular Python data science platform. Anaconda, Inc. continues to lead open source projects like Anaconda, NumPy and SciPy that form the foundation of modern data science. Anaconda’s flagship product, Anaconda Enterprise, allows organizations to secure, govern, scale and extend Anaconda to deliver actionable insights that drive businesses and industries forward.
- [以前一直用rsync同步代码到服务器，这种山寨方法用一次两次还可，每天部署10次就麻烦了，最近抽空研究了一下Fabric，发现这个东西部署起来简直太爽了。](https://www.liaoxuefeng.com/article/001373892650475818672edc83c4c978a45195eab8dc753000)

- cmdb
